{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "Agora vamos tentar praticar um pouco sobre como normalizar nossos dados.\n",
    "User a classe StanderScaler do Sklearn para estandatizar antes de uma regressão linear. \n",
    "\n",
    "\n",
    "Para concluir, siga as etapas abaixo:\n",
    "\n",
    "1. Carregue os dados\n",
    "\n",
    "    Os dados estão no arquivo chamado 'data.csv'. Observe que não há linha de cabeçalho neste arquivo.\n",
    "    Divida os dados para que os seis features preditoras (primeiras seis colunas) sejam armazenados em X e o resultado (última coluna) seja armazenado em y.\n",
    "\n",
    "\n",
    "2. Execute o dimensionamento de recursos nos dados via padronização\n",
    "\n",
    "    Crie uma instância do StandardScaler do sklearn e atribua a variavel scaler.\n",
    "    Calcule os parâmetros de dimensionamento usando o método .fit_transform () na matriz de recursos do preditor, que também retorna as variáveis do preditor em seus valores padronizados. Armazene esses valores padronizados em X_scaled.\n",
    "\n",
    "\n",
    "3. Ajustar dados usando regressão linear com regularização de Lasso\n",
    "\n",
    "    Crie uma instância da classe Lasso do sklearn e atribua-a à variável lasso_reg. Você não precisa definir nenhum valor de parâmetro: use os valores padrão para o questionário.\n",
    "    Use o método .fit () do objeto Lasso para ajustar o modelo de regressão aos dados. Certifique-se de aplicar o ajuste aos dados padronizados da etapa anterior (X_scaled), não aos dados originais.\n",
    "\n",
    "\n",
    "4. Inspecione os coeficientes do modelo de regressão\n",
    "\n",
    "    Obtenha os coeficientes do modelo de regressão de ajuste usando o atributo .coef_ do objeto Lasso. Armazene isso na variável reg_coef: os coeficientes serão impressos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importe as bibliotecas que irá usar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Crie a vaíavel do preditor e de saída. Carregue os dados\n",
    "train_data = pd.read_csv('data.csv', header = None)\n",
    "X = train_data.iloc[:,:-1]\n",
    "y = train_data.iloc[:,-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = train_test_split(train_data.iloc[:,:-1], train_data.iloc[:,-1], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crie o objeto de normalização\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crie e de fit do objeto de normalização\n",
    "X_scaled = scaler.fit_transform(X_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crie um modelo de regressão linear\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dê um fit no seu modelo\n",
    "lr.fit(X_scaled, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.85856608e-03  5.27612213e+00  1.04133561e+01 -6.18704694e-01\n",
      " -1.22565933e+01  1.68774522e+00]\n"
     ]
    }
   ],
   "source": [
    "#Pegue e imprima os coeficientes do seu modelo de regressão.\n",
    "reg_coef = lr.coef_\n",
    "print(reg_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predito = lr.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65.82979866, 44.83985993, 13.62366917, 73.75651577, 42.56105671])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predito[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²:  -6.786127686388584\n"
     ]
    }
   ],
   "source": [
    "print('R²: ', lr.score(X_teste, y_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  1940.2265356923494\n"
     ]
    }
   ],
   "source": [
    "print('MSE: ', mean_squared_error(y_teste, predito))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  37.125111509216744\n"
     ]
    }
   ],
   "source": [
    "print('MAE: ', mean_absolute_error(y_teste, predito))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.85856608e-03,  5.27612213e+00,  1.04133561e+01, -6.18704694e-01,\n",
       "       -1.22565933e+01,  1.68774522e+00])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  -0.009858566079575694\n",
      "1  :  5.276122130446721\n",
      "2  :  10.413356065166655\n",
      "3  :  -0.6187046944903595\n",
      "4  :  -12.256593300714483\n",
      "5  :  1.6877452179873818\n"
     ]
    }
   ],
   "source": [
    "for i,coef in enumerate(lr.coef_):\n",
    "    print(train_data.columns[i],' : ', coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
